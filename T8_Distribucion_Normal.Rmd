---
title: "T8_Distribucion_Normal"
output: 
  html_document:
    toc: yes
    toc_float: yes
    css: custom.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)

```


```{r, eval=TRUE, echo=FALSE}
colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, 
      x)
  } else x
}

#`r colorize("some words in red", "red")`


```

Fecha de la ultima revisión
```{r echo=FALSE}

Sys.Date()
```


# Instalar y activar los siguientes paquete

Para instalar el paquete **modeest** es necesario instalar foes otros paquetes antes, **BiocManager** y **genefilter**.  Usando el siguiente script pora instalar los paquetes.  Nota que en la consola tendrá que aceptar a instalar y seleccionar la "a" para "all".  
Chunk #1

```{r, eval=FALSE}

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("genefilter")


```


```{r packages, eval=FALSE}

if (!require("pacman")) install.packages("pacman")
pacman::p_load( car, GGally, ggversa, pastecs, psych, pander, ggplot2, nortest, Hmisc, boot, knitr, modeest)
R.version

```


Activar los Paquetes
```{r, warning=FALSE}
library(nortest) # paquete para probar la normalidad
library(car) # paquete para análisis de correlación
library(ggplot2)  # paquete para visualizar los datos
library(ggversa) # paquete para diferentes conjuntos de datos
library(modeest) # paquete para calcular la moda 
library(GGally) # Un paquete basado un ggplot2 para visualizar correlaciones 
library(pastecs) # paquete para análisis tiempo-espacial usado en ecología 
library(psych) # paquete para análisis psicométrica, psicológica y de personalidad 
library(Hmisc) # Un grupo de función prácticos para gráficos y tablas
library(boot) # paquete para calcular los intervalos usando "bootstrap" 
library(knitr) # un grupo de función para incluyendo tablas bonitas con kable. 

```

***

# La distribución normal 

 
Es modulo está enfocado en entender diferentes aspectos de la distribución normal. Muchas pruebas como la prueba de t, correlaciones, regresiones y ANOVA depende que algunos de los conjuntos de datos cumple con una distribución normal. Este tipo de pruebas se pueden referir a pruebas paramétricas.  

La distribución normal tiene una ecuación que describe su distribución.  Lo que que se observa es que la ecuación depende de solamente dos valores desconocidos, el promedio universal, µ y la desviación universal $\sigma$. Nota que aquí estamos considerando todos los datos sobre un variable. Por ejemplo si esta hablando de del tamaño de un especie de pájaro ( El quetzal), es que tendríamos que tener TODOS los datos de cada uno de ellos.   Primero vemos como se ve esta distribución y después explicamos porque aunque no tenemos todos los datos una aproximación es suficiente.   


 $$P(x)=\frac{1}{{\sigma\sqrt{ 2\pi}}}{e}^{-\frac{{(x-µ)}^{2}}{{2\sigma}^{2}}}$$
 


El promedio de la población $\mu=\frac{\sum{{x}_{i}}}{{n}_{i}}$, se usa la letra "mu", y se refiere al promedio universal.  Esto quiere decir que no falta ningún dato.  Nota que la distribución es en forma de campana, donde 50% de los datos están por encima del promedio y 50% están por debajo el promedio. Debido que la distribución tiene unos parámetros específico se puede predecir información cuando los datos cumple con tal distribución.      


```{r}
set.seed(12345)
dfnorm=rnorm(1000000, 0,1)
dfnorm=data.frame(dfnorm)

ggplot(dfnorm,(aes(x=dfnorm)))+
  geom_density()+
  geom_vline(xintercept = 0, colour="red")+
  annotate("text", x=.8, y = .1, label="50% de los \n valores")+
  annotate("text", x=-.8, y = .1, label="50% de los \n valores")+
  xlab("algun valor")+
  ylab("densidad")
```

***

## Evaluando visualmente la distribución

El primer paso de cada investigación es evaluar si los supuestos se cumplen. Si las pruebas necesitan tener una distribución normal uno de los métodos más sencillo construir un histograma de los datos.  

Usaremos datos que hemos visto en el modulo T5.  

Se necesita el archivo **DownloadFestival** que se encuentra debajo la pestaña de **Los Datos**. El ejemplo proviene de Field et al. (2014).


>  Una bióloga estaba preocupado por los posibles efectos sobre la salud de los que particpan a un festivales de música. Entonces, un año fue al Download Festival en el Reino Unido (Download Festival UK). Ella midió la higiene del los que participaron al concierto n= 810 durante el festival de 3 días. Cada día intentaba encontrar a todas las personas que censó el primer día. Los valores asignado fueron de 0 a 4 sobre el nivel de limpieza por como olia los participantes

>    + 0 = hueles como un cadáver. 
>    + 4 = hueles a rosas dulces en un fresco día de primavera
    

```{r, warning=FALSE}

library(readr)
DownloadFestival_No_Outlier_ <- read_csv("Data_files_csv/DownloadFestival(No Outlier).csv")



dlf=DownloadFestival_No_Outlier_  #usamos un nombre más corta para facilitar  
head(dlf) # ver las 3 primeras filas

```

Se nota en el histograma que la mayoría de los datos de la higiene de los participantes en el primer día se parece bastante a una distribución normal.  Nota que los valores en el eje de **y** es la frecuencia de los valores en el conjunto de datos.  

```{r}
ggplot(dlf, aes(day1))+
  geom_histogram(color="white", fill="red")
```
***

# Añadiendo la distribución teórica al histograma


Ahora vamos a añadir la siguiente formula al gráfico  $P(x)=\frac{1}{{\sigma\sqrt{ 2\pi}}}{e}^{-\frac{{(x-µ)}^{2}}{{2\sigma}^{2}}}$.  De esta forma podemos comparar los datos reales (las barras roja) con la distribución teorica si el promedio y la desviación estandar es igual a los datos.  

Se añade el promedio y la desviación estándar con la siguientes funciones.  La función *stat_function()** es para calcular parámetros.  
                
                stat_function(fun = dnorm,   # dnorm = la densidad de la distribución normal
                args = list(
                mean = mean(dlf$day2, na.rm = TRUE), # mean = el promedio de los datos
                sd = sd(dlf$day2, na.rm = TRUE))) # sd = la desviación estandar de los datos


Ahora nota que el eje de **y** no son frecuencias pero son densidades.  La suma de todas las densidades es igual a 1.0.  Vea que la linea teórica se acerca bastante a las barras del histograma.   Este proceso NO es una prueba para determinar si los datos cumple con una distribución normal. Aunque con experiencia visualizando los datos uno puede tener un buen apreciación si los datos cumple suficientemente con la distribución normal para usar las pruebas paramétricas.   

 
```{r, warning=FALSE, message=FALSE}
hist.dlfc1 <- ggplot(dlf, aes(day1)) + 
  geom_histogram(aes(y=..density..), colour="white", fill="red") + 
  labs(x="Higiene día 1", y = "Densidad")+
  stat_function(fun = dnorm, 
                args = list(mean = mean(dlf$day1, na.rm = TRUE), 
                sd = sd(dlf$day1, na.rm = TRUE)), 
                colour = "green", size = 1)

hist.dlfc1


```


## Evaluando otros datos 

Usamos los datos del segundo día y comparamos con el primer día.  En este caso vemos que los datos no siguen una distribución normal están sesgados a la izquierda y vemos que "falta" valores pequeños, en otra palabra en este caso los valores negativos.   

Evalúa y compara con el día tres

```{r, warning=FALSE}
hist.dlfc2 <- ggplot(dlf, aes(day2)) + 
  geom_histogram(aes(y=..density..), colour="white", fill="blue") + 
  labs(x="Higiene día 2", y = "Densidad")+
  stat_function(fun = dnorm, 
                args = list(mean = mean(dlf$day2, na.rm = TRUE), 
                sd = sd(dlf$day2, na.rm = TRUE)), 
                colour = "yellow", size = 2)

hist.dlfc2
```







# What would be a normal distribution of your own data
 Here I created a function where you can use it to explore what to expect from a random sample a some survey/experiments you are doing.  

We can use the function "rnorm" to create a data set that has a normal distribution, with a specific mean and standard deviation. 
rnorm(n, mean, sd)
rnorm = (select n values, mean of x, sd of x), n= the number of values you want to select

calculate the mean and sd. 

```{r historgram normal, warning=FALSE}

#rnorm(10, 100, 10)

x=rnorm(10000, 10, 2)

dfx=data.frame(x)
head(dfx)
library(ggplot2)
hist.x <- ggplot(dfx, aes(x)) + 
  theme(legend.position = "none") + 
  geom_histogram(aes(y=..density..), bins=30,colour="black", fill="white") + 
  labs(x="Variable", y = "Densidad")+
  stat_function(fun = dnorm, args = list(mean = mean(dfx$x, 
                na.rm = TRUE), 
                sd = sd(dfx$x, na.rm = TRUE)), 
                colour = "red", size = 1)

hist.x
```



#  qqplot




Add a straight line on the qqplot
```{r qqplot and line, warning=FALSE}


ggplot(dlf, aes(sample=day1))+
  geom_qq()+
  geom_qq_line()

```

# Now check the qq plot for day 2 and day 3


```{r line day 2, warning=FALSE}

```

```{r line day 3, warning=FALSE}

```



 
## Tests of Normality
### A.

#### Shapiro-Wilks test
Problem, sensitive to sample size
 1. should not be used with less than 50 data points
 2. should not be used for sample size of over 200....
 

```{r shapiro, warning=FALSE}
shapiro.test(dlf$day1)
length(dlf$day1)
```

### B. 
#### Other normality test, use the package "nortest"

Anderson-Darling test for normality, 


The Anderson-Darling test is an EDF omnibus test for the composite hypothesis of normality. 
Omnibus tests are a kind of statistical test. They test whether the explained variance in a set of data is significantly greater than the unexplained variance, overall.


```{r norm test, warning=FALSE}
library(nortest)

ad.test(dlf$day1)

```




Capitulo 15
5.  Summary statistics, individual appraoch, summary
  1. Mean
  2. Median  
  3. Mode
  4. Skewness and Kurtosis
 
```{r summary stat, warning=FALSE}
x=sample(1:100, size=100, replace = TRUE)
x=data.frame(x)
head(x)
mean(x$x)
var(x$x)
sd(x$x)
min(x$x)
max(x$x)
```
 
Mean = mean
Variance =var 
Standard deviation = sd
mimimum value of a variable = min
maximum value of a variable = max
median value of a variable = median
 
```{r summary stat 2, warning=FALSE}


mean(dlf$day2, na.rm=TRUE)
var(dlf$day1, na.rm=TRUE)
sd(dlf$day1, na.rm=TRUE)
min(dlf$day1, na.rm=TRUE)
max(dlf$day1, na.rm=TRUE)
median(dlf$day1, na.rm=TRUE)


```

Start Here
 

 Summary stats
 
 
```{r summary function, warning=FALSE}

summary(dlf$day1, na.rm=TRUE)  

# the "describe" function is the "psych" package
library(psych)
describe(dlf[,c("day1","day2","day3")]) 


# the "stat.desc" function is the "pastec" package
stat.desc(dlf[,c("day1","day2","day3")], basic=FALSE,norm=TRUE)


round(stat.desc(dlf[,c("day1","day2","day3")], basic=FALSE,norm=TRUE), digits=3) # reduce to 3 significant figures
```
 
 
 
 Quantiles
 
```{r quantiles, warning=FALSE}

quantile(dlf$day1,probs=c(0.05, 0.1, 0.25, 0.5,.55, 0.75, 0.95, 0.99), na.rm=TRUE)
```
 
 

 
 
